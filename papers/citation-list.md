# List of Paper Reference

Numbering of papers in all files should follow this. Some papers may have local copy since we'll more frequently refer to them than others. Some papers come with reviews.

1. Anh Nguyen et al. "Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images." [local](dnn-fooling-1412.1897.pdf)/[arXiv link](https://arxiv.org/pdf/1412.1897.pdf)

2. Yangqing Jia et al. "Caffe: Convolutional Architecture for Fast Feature Embedding." [arXiv link](https://arxiv.org/pdf/1408.5093.pdf)

3. Nicolas Papernot et al. "Practical black-box attacks against deep learning systems using adversarial examples." [local](black-box-1602.02697.pdf)/[arXiv link](https://arxiv.org/pdf/1602.02697.pdf)

4. Ian J. Goodfellow et al. "Explaining and Harnessing Adversarial Examples." [arXiv link](https://arxiv.org/pdf/1412.6572.pdf)

5. Alexey Kurakin et al. "Adversarial Examples in the Physical World." [arXiv link](https://arxiv.org/pdf/1607.02533.pdf)

6. Robin Jia, Percy Liang. "Adversarial Examples for Evaluating Reading Comprehension Systems." [local](nlp/eval-reading-system-1707.07328.pdf)/[arXiv link](https://arxiv.org/pdf/1707.07328.pdf)

7. Yuchi Tian et al. "DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars." [arXiv link](https://arxiv.org/pdf/1708.08559.pdf)

8. Emiel van Miltenburg. "Stereotyping and Bias in the Flickr30K Dataset." [arXiv link](https://arxiv.org/pdf/1605.06083.pdf)

9. Papernot et al. "The Limitations of Deep Learning in Adversarial Settings." [arXiv Link](https://arxiv.org/pdf/1511.07528.pdf)

10. Karon Simonyan et al. "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps." [arXiv Link](https://arxiv.org/pdf/1312.6034.pdf)

11. Zhengli Zhao et al. "Generating Natural Adversarial Examples." [arXiv Link](https://arxiv.org/pdf/1710.11342.pdf)